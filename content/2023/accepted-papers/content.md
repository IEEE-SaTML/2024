+++ 
fragment = "content" 
#disabled = true 
date = "2022-11-12" 
weight = 100
#background = ""

title = "Accepted Papers 2023" #subtitle = "" 

+++


There were 40 papers accepted out of 152 submissions; resulting in an acceptance
rate of 26.3%. For more details about the 3 types of papers that were accepted
at SaTML 2023, check our [call for papers](/2023/participate-cfp).

Two best paper awards were announced at the conference:
* *SoK: A Validity Perspective on Evaluating the Justified Use of Data-driven Decision-making Algorithms*
by Amanda Coston (Carnegie Mellon University, USA), Anna Kawakami (Carnegie Mellon University, USA), Haiyi Zhu (Carnegie Mellon University, USA), Ken Holstein (Carnegie Mellon University, USA), andHoda Heidari (Carnegie Mellon University, USA).
* *Optimal Data Acquisition with Privacy-Aware Agents* by Rachel Cummings (Columbia University), Hadi Elzayn (Stanford University), Emmanouil Pountourakis (Drexel University), Vasilis Gkatzelis (Drexel University), and Juba Ziani (Georgia Institute of Technology).


Conference attendees can access the proceedings <a href="https://conferences.computer.org/satmlpub/#!/toc/0" target="_blank">here</a> (username and password communicated at the conference).


#### Systematization of Knowledge (SoK) Papers

<ol class="list-group mb-3 mt-3">

<!-- override OpenReview output for Kamalika to University of California, San Diego -->

<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>SoK: Harnessing Prior Knowledge for Explainable Machine Learning: An Overview</b></div>Katharina Beckh (Fraunhofer IAIS, Germany), Sebastian Müller (University of Bonn, Germany), Matthias Jakobs (TU Dortmund University, Germany), Vanessa Toborek (University of Bonn, Germany), Hanxiao Tan (TU Dortmund University, Germany), Raphael Fischer (TU Dortmund University, Germany), Pascal Welke (University of Bonn, Germany), Sebastian Houben (Hochschule Bonn-Rhein-Sieg, Germany), and Laura von Rueden (Fraunhofer IAIS, Germany)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=1KE7TlU4bOt" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>SoK: A Validity Perspective on Evaluating the Justified Use of Data-driven Decision-making Algorithms</b></div>Amanda Coston (Carnegie Mellon University, USA), Anna Kawakami (Carnegie Mellon University, USA), Haiyi Zhu (Carnegie Mellon University, USA), Ken Holstein (Carnegie Mellon University, USA), andHoda Heidari (Carnegie Mellon University, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=LghfT9-phCc" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>SoK: Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks</b></div>Tilman Rauker (n/a), Anson Ho (Epoch), Stephen Casper (MIT CSAIL), and Dylan Hadfield-Menell (MIT CSAIL)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=8C5zt-0Utdn" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>




</ol>


#### Research Papers




<ol class="list-group mb-3 mt-3">




<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Reducing Certified Regression to Certified Classification for General Poisoning Attacks</b></div>Zayd Hammoudeh (University of Oregon, USA) and Daniel Lowd (University of Oregon, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=PWf0OsvK43F" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Theoretical Limits of Provable Security Against Model Extraction by Efficient Observational Defenses</b></div>Ari Karchmer (Boston University)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=gKFGYd3GEaL" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Towards Transferable Unrestricted Adversarial Examples with Minimum Changes</b></div>Fangcheng Liu (Peking University), Chao Zhang (Peking University), and Hongyang Zhang (University of Waterloo</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=PvuoLIuWBsR" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>PolyKervNets: Activation-free Neural Networks For Efficient Private Inference</b></div>Toluwani Aremu (Mohamed Bin Zayed Institute of Artificial Intelligence, UAE) and Karthik Nandakumar (Mohamed Bin Zayed Institute of Artificial Intelligence, UAE</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=OGzt9NKC0lO" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Exploiting Fairness to Enhance Sensitive Attributes Reconstruction</b></div>Julien Ferry (LAAS-CNRS, Université de Toulouse, CNRS, France), Ulrich Aïvodji (Ecole de Technologie Supérieure, Canada), Sébastien Gambs (Université du Québec à Montréal, Canada), Marie-José Huguet (LAAS-CNRS, Université de Toulouse, CNRS, INSA, France), and Mohamed Siala (LAAS-CNRS, Université de Toulouse, CNRS, INSA, France)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=tOVr0HLaFz0" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>ExPLoit: Extracting Private Labels in Split Learning</b></div>Sanjay Kariyappa (Georgia Institute of Technology) and Moinuddin K Qureshi (Georgia Institute of Technology)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=0nrrpSTPKq3" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy for Deep Learning?</b></div>Guy Heller (University of Bar-Ilan, Ramat Gan, Israel) and Ethan Fetaya (University of Bar-Ilan, Ramat Gan, Israel)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=52v6nG6EvkfG" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>A Light Recipe to Train Robust Vision Transformers</b></div>Edoardo Debenedetti (ETH Zurich, Switzerland), Vikash Sehwag (Princeton University, USA), and Prateek Mittal (Princeton University, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=IztT98ky0cKs" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>SafeNet: The Unreasonable Effectiveness of Ensembles in Private Collaborative Learning</b></div>Harsh Chaudhari (Northeastern University), Matthew Jagielski (Google Research), and Alina Oprea (Northeastern University)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=cpB6OIILpl_p" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Explainable Global Fairness Verification of Tree-Based Classifiers</b></div>Stefano Calzavara (Università Ca' Foscari Venezia, Italy), Lorenzo Cazzaro (Università Ca' Foscari Venezia, Italy), Claudio Lucchese (Università Ca' Foscari Venezia, Italy), and Federico Marcuzzi (Università Ca' Foscari Venezia, Italy)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=HOu7LgqCTqd" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Endogenous Macrodynamics in Algorithmic Recourse</b></div>Patrick Altmeyer (Delft University of Technology, The Netherlands), Giovan Angela (Delft University of Technology, The Netherlands), Aleksander Buszydlik (Delft University of Technology, The Netherlands), Karol Dobiczek (Delft University of Technology, The Netherlands), Arie van Deursen (Delft University of Technology, The Netherlands), and Cynthia C. S. Liem (Delft University of Technology, The Netherlands)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=-LFT2YicI9v" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>No Matter How You Slice It: Machine Unlearning with SISA Comes at the Expense of Minority Classes</b></div>Korbinian Koch (Universität Hamburg, Germany) and Marcus Soll (NORDAKADEMIE gAG Hochschule der Wirtschaft, Germany)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=RBX1H-SGdT" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Optimal Data Acquisition with Privacy-Aware Agents</b></div>Rachel Cummings (Columbia University), Hadi Elzayn (Stanford University), Emmanouil Pountourakis (Drexel University), Vasilis Gkatzelis (Drexel University), and Juba Ziani (Georgia Institute of Technology)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=VPQBK20cvC" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Dissecting Distribution Inference</b></div>Anshuman Suri (University of Virginia), Yifu Lu (University of Michigan), Yanjin Chen (University of Virginia), and David Evans (University of Virginia)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=xq-vwexwlUl" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Reprogrammable-FL: Improving Utility-Privacy Tradeoff in Federated Learning via Model Reprogramming</b></div>Huzaifa Arif (Rensselaer Polytechnic Institute, USA), Alex Gittens (Rensselaer Polytechnic Institute, USA), and Pin-Yu Chen (IBM Research, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=00EiAK1LHs" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Data Redaction from Pre-trained GANs</b></div>Zhifeng Kong (University of California San Diego, USA) and Kamalika Chaudhuri (University of California San Diego, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=bYV3bK_Azi" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Sniper Backdoor: Single Client Targeted Backdoor Attack in Federated Learning</b></div>Gorka Abad (Radboud University, The Netherlands; Ikerlan research centre, Spain), Servio Paguada (Radboud University, The Netherlands; Ikerlan research centre, Spain), Oguzhan Ersoy (Radboud University, The Netherlands), Stjepan Picek (Radboud University, The Netherlands), Víctor Julio Ramírez-Durán (Ikerlan research centre, Spain), and Aitor Urbieta (Ikerlan research centre, Spain)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=P90zTbrvvz" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Backdoor Attacks on Time Series: A Generative Approach</b></div>Yujing Jiang (University of Melbourne), Xingjun Ma (Fudan University), Sarah Monazam Erfani (University of Melbourne), and James Bailey (University of Melbourne)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=fuCQFswk0Y" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Kernel Normalized Convolutional Networks for Privacy-Preserving Machine Learning</b></div>Reza Nasirigerdeh (Technical University of Munich, Germany), Javad Torkzadehmahani (Azad University of Kerman, Iran), Daniel Rueckert
(Technical University of Munich, Germany; Imperial College London, United Kingdom), and Georgios Kaissis (Technical University of Munich, Germany; Helmholtz Zentrum Munich, Germany; Imperial College London, United Kingdom)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=pyfGjjDmrC" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Publishing Efficient On-device Models Increases Adversarial Vulnerability</b></div>Sanghyun Hong (Oregon State University), Nicholas Carlini (Google Brain), and Alexey Kurakin (Google Brain)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=nbNdDm1x3c" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Wealth Dynamics Over Generations: Analysis and Interventions</b></div>Krishna Acharya (Georgia Institute of Technology, USA), Eshwar Ram Arunachaleswaran (University of Pennsylvania, USA), Sampath Kannan (University of Pennsylvania, USA), Aaron Roth (University of Pennsylvania, USA), and Juba Ziani (Georgia Institute of Technology, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=p9YQ-rGXB-L" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>EDoG: Adversarial Edge Detection For Graph Neural Networks</b></div>Xiaojun Xu (University of Illinois at Urbana-Champaign), Hanzhang Wang (eBay), Alok Lal (eBay), Carl Gunter (University of Illinois at Urbana-Champaign), and Bo Li (University of Illinois at Urbana-Champaign)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=ZFHlFRYQPUB" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Neural Lower Bounds for Verification</b></div>Florian Jaeckle (University of Oxford, UK) and M. Pawan Kumar (University of Oxford, UK)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=BIfOAxQzlt" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Less is More: Dimension Reduction Finds On-Manifold Adversarial Examples in Hard-Label Attacks</b></div>Washington Garcia (University of Florida), Pin-Yu Chen (IBM Research), Hamilton Clouse (Air Force Research Laboratory), Somesh Jha (University of Wisconsin), and Kevin Butler (University of Florida)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=4E3Jm0p6Sc" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Learning Fair Representations through Uniformly Distributed Sensitive Attributes</b></div>Patrik Joslin Kenfack (Innopolis University, Russia), Adín Ramírez Rivera (University of Oslo, Norway), Adil Mehmood Khan (Innopolis University, Russia; University of Hull, UK), and Manuel Mazzara (Innopolis University, Russia)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=iW7r_6LuHwA" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>CARE: Certifiably Robust Learning with Reasoning via Variational Inference</b></div>Jiawei Zhang (University of Illinois Urbana-Champaign, USA), Linyi Li (University of Illinois Urbana-Champaign, USA), Ce Zhang (ETH Zürich, Switzerland), and Bo Li (University of Illinois Urbana-Champaign, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=1n6oWTTV1n" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Toward Certified Robustness Against Real-World Distribution Shifts</b></div>Haoze Wu (Stanford University, USA), Teruhiro Tagomori (Stanford University, USA; NRI Secure, Japan), Alexander Robey (University of Pennsylvania, USA), Fengjun Yang (University of Pennsylvania, USA), Nikolai Matni (University of Pennsylvania, USA), George Pappas (University of Pennsylvania, USA), Hamed Hassani (University of Pennsylvania, USA), Corina Pasareanu (Carnegie Mellon University, USA), and Clark Barrett (Stanford University, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=hVAK0cgiWrU" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>What Are Effective Labels for Augmented Data?  Improving Calibration and Robustness with AutoLabel</b></div>Yao Qin (Google Research, USA), Xuezhi Wang (Google Research, USA), Balaji Lakshminarayanan (Google Research, USA), Ed H. Chi (Google
Research, USA), and Alex Beutel (Google Research, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=FQqOHhtUpl2" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>VENOMAVE: Targeted Poisoning Against Speech Recognition</b></div>Hojjat Aghakhani (University of California, Santa Barbara), Lea Schönherr (CISPA Helmholtz Center for Information Security), Thorsten Eisenhofer (Ruhr University Bochum), Dorothea Kolossa (Technische Universität Berlin), Thorsten Holz (CISPA Helmholtz Center for Information Security), Christopher Kruegel (University of California, Santa Barbara), and Giovanni Vigna (University of California, Santa Barbara)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=4lIXrDF6C3KF" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>FaShapley: Fast and Approximated Shapley Based Model Pruning Towards Certifiably Robust DNNs</b></div>Mintong Kang (University of Illinois at Urbana-Champaign), Linyi Li (University of Illinois at Urbana-Champaign), and Bo Li (University of Illinois at Urbana-Champaign)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=mJF9_Fs52ut" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Model Inversion Attack with Least Information and an In-depth Analysis of its Disparate Vulnerability</b></div>Sayanton V. Dibbo (Dartmouth College), Dae Lim Chung (Dartmouth College), and Shagufta Mehnaz (The Pennsylvania State University)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=x42Lo6Mkcrf" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>ModelPred: A Framework for Predicting Trained Model from Training Data</b></div>Yingyan Zeng (Virginia Tech, USA), Jiachen T. Wang (Princeton University, USA), Si Chen (Virginia Tech, USA), Hoang Anh Just (Virginia Tech, USA), Ran Jin (Virginia Tech, USA), and Ruoxi Jia (Virginia Tech, USA)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=I03uWXMi6oD" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Distribution inference risks: Identifying and mitigating sources of leakage</b></div>Valentin Hartmann (EPFL), Léo Meynent (EPFL), Maxime Peyrard (EPFL), Dimitrios Dimitriadis (Amazon), Shruti Tople (Microsoft Research), and
Robert West (EPFL)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=Y3txj7WM1dL" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Counterfactual Sentence Generation with Plug-and-Play Perturbation</b></div>Nishtha Madaan (IBM Research India; Indian Institute of Technology), Diptikalyan Saha (IBM Research India), and Srikanta Bedathur (Indian Institute of Technology)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=mjoSXvVfj4" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Rethinking the Entropy of Instance in Adversarial Training</b></div>Minseon Kim (KAIST, South Korea), Jihoon Tack (KAIST, South Korea), Jinwoo Shin (KAIST, South Korea), and Sung Ju Hwang (KAIST, South Korea; AITRICS, South Korea)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=DdSI8i31ef" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>




</ol>




#### Position Papers

<ol class="list-group mb-3 mt-3">


<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Position: “Real Attackers Don’t Compute Gradients”: Bridging the Gap Between Adversarial ML Research and Practice</b></div>Giovanni Apruzzese (University of Liechtenstein), Hyrum S. Anderson (Robust Intelligence), Savino Dambra (Norton Research Group), David Freeman (Meta), Fabio Pierazzi (King's College London), and Kevin A. Roundy (Norton Research Group)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=54Jcj2YmJg" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>
<li class="list-group-item d-flex justify-content-between align-items-start"><div class="ms-2 me-auto"> <div class="fw-bold"><b>Position: Tensions Between the Proxies of Human Values in AI</b></div>Teresa Datta (Arthur), Daniel Nissani (Arthur), Max Cembalest (Arthur), Akash Khanna (Arthur), Haley Massa (Arthur), and John Dickerson (Arthur)</div><span class="badge bg-danger rounded-pill"><a href="https://openreview.net/forum?id=7EjikkMkIl" target="_blank" style="text-decoration: none; color: white;">OpenReview</a></span></li>




</ol>